from kafka import KafkaConsumer
import json
import time
import os
import pandas as pd
from dotenv import load_dotenv

from anomaly_detector import AnomalyDetector
from xai_shap import AnomalyXAI

load_dotenv()

# --- 1. í™˜ê²½ ë³€ìˆ˜ ---
KAFKA_BROKER_ADDR = os.environ.get('KAFKA_BROKER_ADDR') 
KAFKA_BROKER_PORT = os.environ.get('KAFKA_BROKER1_PORT')
KAFKA_BROKER = f"{KAFKA_BROKER_ADDR}:{KAFKA_BROKER_PORT}"
TOPIC_NAME = os.environ.get('TOPIC_NAME')

# --- [ì„¤ì •] ì´ìƒ íƒì§€ê¸° ì´ˆê¸°í™” ---
detector = AnomalyDetector(
    model_path="autoencoder_model.pth",
    scaler_path="scaler.pkl",
    columns_path="columns.pkl",
    threshold=0.183441
)

# --- [ì¶”ê°€] XAI Explainer ì´ˆê¸°í™” ---
# ì£¼ì˜: SHAP ë¶„ì„ì„ ìœ„í•´ 'ì •ìƒ ë°ì´í„° ìƒ˜í”Œ'ì´ í•„ìš”í•©ë‹ˆë‹¤.
# íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ DataFrameìœ¼ë¡œ ì‹œì‘í•˜ë©° ê²½ê³ ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
xai_explainer = None
if os.path.exists("normal_samples.csv"):
    try:
        background_df = pd.read_csv("normal_samples.csv")
        # ê³„ì‚° ì†ë„ë¥¼ ìœ„í•´ ìƒ˜í”Œ ìˆ˜ë¥¼ 50ê°œ ì •ë„ë¡œ ì œí•œí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        if len(background_df) > 50:
            background_df = background_df.sample(50, random_state=42)
        
        xai_explainer = AnomalyXAI(detector, background_df)
        print("[System] XAI Explainer ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"[System Error] XAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
else:
    print("[Warning] 'normal_samples.csv'ê°€ ì—†ì–´ XAI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")




# --- 2. JSON Deserializer í•¨ìˆ˜ ---
def deserializeJson(m):
    try:
        # ë°”ì´íŠ¸ë¥¼ ë””ì½”ë”©í•˜ê³  JSONì„ ë¡œë“œ
        return json.loads(m.decode('utf-8'))
    except json.JSONDecodeError as e:
        print(f"JSON ë””ì½”ë”© ì˜¤ë¥˜ ë°œìƒ: {e}. Raw Data: {m[:50]}...")
        return None

# --- 3. ë©”ì¸ ì»¨ìŠˆë¨¸ ë£¨í”„ ---
def startConsumer():
    # Kafka Consumer ì„¤ì •
    
    consumer = KafkaConsumer(
        TOPIC_NAME,
        bootstrap_servers=[KAFKA_BROKER],
        auto_offset_reset='earlist', # ì €ì¥ëœ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì²˜ìŒë¶€í„° í™•ì¸
        enable_auto_commit=False, 
        group_id='group1',
        value_deserializer=deserializeJson 
    )

    print(f"\n[{time.strftime('%H:%M:%S')}] ë””ë²„ê·¸ ì»¨ìŠˆë¨¸ ì‹œì‘. ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤...")
    
    try:
        for message in consumer:
            flow_data = message.value
            print(f"[Raw Data]: {flow_data}\n")
            if flow_data is None: continue

            # ì´ìƒ íƒì§€ ìˆ˜í–‰
            is_anomaly, loss = detector.detect(flow_data)
            
            # ê²°ê³¼ ì¶œë ¥ í¬ë§·íŒ…
            status_msg = "ğŸ”´ ANOMALY" if is_anomaly else "ğŸŸ¢ NORMAL"
            
            print("-" * 50)
            print(f"Partition: {message.partition} | Offset: {message.offset} | {status_msg}")
            print(f"Loss  : {loss:.6f} (Threshold: {detector.threshold})")
	    
            if is_anomaly and xai_explainer is not None:
                print("   >> ì´ìƒ ì›ì¸ ë¶„ì„(SHAP) ìˆ˜í–‰ ì¤‘...")
                top_features = xai_explainer.analyze_and_save(
                    flow_data, 
                    loss, 
                    message.partition, 
                    message.offset
                )
                print(f"   >> ì£¼ìš” ì›ì¸ í”¼ì²˜ Top 3: {top_features}")

#            ë©”ì‹œì§€ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ ì¶œë ¥í•˜ê±°ë‚˜, í•„ìš”ì‹œ ì „ì²´ ì¶œë ¥
#            print(f"Data  : {flow_data}")

#            print(f"  Offset: {message.offset}")
#            print(f"  message : {message.value}")
            
    except KeyboardInterrupt:
        print("\n[INFO] ì»¨ìŠˆë¨¸ ì¢…ë£Œ ìš”ì²­ ê°ì§€.")
    except Exception as e:
        print(f"[FATAL] ì˜ˆì™¸ ë°œìƒ: {e}")
    finally:
        consumer.close()
        print("[INFO] ì»¨ìŠˆë¨¸ ì—°ê²°ì´ ë‹«í˜”ìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    startConsumer()
